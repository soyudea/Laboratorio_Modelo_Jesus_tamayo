{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soyudea/Laboratorio_Modelo_Jesus_tamayo/blob/main/Laborator_1_OmarTorres_91220873.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypd4WuxpWQU4"
      },
      "source": [
        "# Laboratorio 1 - Parte 1\n",
        "\n",
        "### Regresión polinomial múltiple\n",
        "\n",
        "### Universidad de Antioquia\n",
        "\n",
        "### Facultad de Ingeniería\n",
        "\n",
        "### Ingeniería de Sistemas\n",
        "\n",
        "### UdeA - Ude@\n",
        "\n",
        "#### Profesor: Ph. D. (c) Antonio Jesús Tamayo Herrera\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytnKSoOLWQU8"
      },
      "source": [
        "### Estudiantes\n",
        "\n",
        "#### Nombre: Omar Alberto Torres\n",
        "\n",
        "#### Cédula: 91220873\n",
        "\n",
        "#### Nombre:\n",
        "\n",
        "#### Cédula:\n",
        "\n",
        "#### Nombre:\n",
        "\n",
        "#### Cédula:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy-VPDGNWQU9"
      },
      "source": [
        "## Guía del laboratorio\n",
        "\n",
        "En este archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
        "\n",
        "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyPZURB0WQU9"
      },
      "source": [
        "## Ejercicio 1\n",
        "\n",
        "A continuación se define la función sigmoidal. En la parte del código dónde está el comentario (Complete ...) debe escribir el código que permita calcular la salida de dicha función. Es decir, escriba una función en Python para la siguiente función matemática:\n",
        "\n",
        "$$ g(z) = \\frac{1}{1+e^{-z}} $$\n",
        "\n",
        "Realice la gráfica de la función sigmoidal para valores de $z$ entre $-5$ y $5$. La gráfica debe tener título y los correspondientes nombres de los ejes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "1R-uVJPsWQU-",
        "outputId": "b89d4742-66ae-48e3-f841-54812ae0b388"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from __future__ import division\n",
        "import math\n",
        "\n",
        "#Sigmoidal\n",
        "def sigmoidal(z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "z =np.arange(-5,5,0.01)   \n",
        "y = sigmoidal(z)\n",
        "plt.plot(z,y)\n",
        "plt.xlabel(\"Rango [-5,5,0.5\")\n",
        "plt.ylabel(\"Funcion(z) = 1/(1 + exp(z)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nti9O3oZx_eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[1,2],[3,4],[5,6]])\n",
        "y = np.array(np.ones([np.size(X, axis=0)]))\n",
        "d = np.size(X)\n",
        "w=np.zeros(d)\n",
        "\n",
        "w = w.reshape(np.size(w),1)\n",
        "y = y.reshape(np.size(y),1)\n",
        "w = np.zeros(5)\n",
        "w\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ve6GLNQQoWD",
        "outputId": "d06d1cab-e0b2-4f48-8104-80c4ac7342f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bza_ddAWQU_"
      },
      "source": [
        "## Ejercicio 2\n",
        "\n",
        "Analice los siguientes métodos a la luz de la teoría vista para los modelos de regresión polinomial múltiple. Una vez comprenda su funcionamiento, proceda a completar el código del método de gradiente descendente para el problema de regresión. En este método se le pide escribir el código de la regla de actualización de los parámetros del algorítmo de gradiente descedente: \n",
        "\n",
        "$$w_j(iter) = w_j(iter-1) - \\eta \\frac{\\partial E(w)}{\\partial w_j}$$ \n",
        "\n",
        "y además se pide graficar el error cuadrático \n",
        "medio (ECM) vs. las iteraciones del algorítmo. La gráfica debe llevar título y los correspondientes nombres de los ejes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.ones((3,2))\n",
        "b = np.reshape(a,(2,3))\n",
        "print(b.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQv2KGmnmrZK",
        "outputId": "cdde861e-05a9-43a9-d4b1-0f451f55d090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qx5g_-BWQVA"
      },
      "outputs": [],
      "source": [
        "#Error cuadrático medio (criterio para el modelo de regresión polinomial)\n",
        "#El código recibe el valor estimado de y y el valor teorico Y\n",
        "def ECM(Y_est,Y):\n",
        "    N = np.size(Y)\n",
        "    ecm = sum((Y_est - Y)**2)/(2*N)\n",
        "    return ecm \n",
        "\n",
        "#Modelo Regresión Múltiple\n",
        "def regression(X, W):\n",
        "    Yest = np.dot(X,W)    #con np.dot se realiza el producto matricial. Aquí X es dim [Nxd] y W es dim [dx1]\n",
        "    return Yest           #La variable Yest contiene la salida de f(X,W)\n",
        "\n",
        "\n",
        "#Potencia de polinomio\n",
        "def potenciaPolinomio(X,grado):\n",
        "    \"\"\"\n",
        "    Este método permite aumentar la matriz (base de datos de entrenamiento)\n",
        "    de tal manera que se incluyan los términos con potencia mayores que 1\n",
        "    de acuerdo al parámetro grado (M) que pase el usuario.\n",
        "    \"\"\"\n",
        "    X2 = X\n",
        "    \n",
        "    if grado != 1:\n",
        "        for i in range(2,grado+1):\n",
        "            Xadd = X**i\n",
        "            X2 = np.concatenate((X2, Xadd), axis=1)\n",
        "    \n",
        "    return X2\n",
        "\n",
        "    \n",
        "#Gradiente descendente para regresión polinomial\n",
        "def gradiente_descendente(X,Y,grado,eta,iterations):\n",
        "    \"\"\"\n",
        "    params:\n",
        "    X: base de datos de entrenamiento (array de numpy)\n",
        "    Y: variable de salida (array de numpy)\n",
        "    grado: grado del polinomio (Natural mayor o igual a 1)\n",
        "    eta: tasa de aprendizaje para el algoritmo de gradiente descendente\n",
        "    (real mayor que cero. Ej: 0.001)\n",
        "    iterations: número de iteraciones del algoritmo de gradiente descendente\n",
        "    \"\"\"\n",
        "\n",
        "    #Se modifica la matriz de datos original de acuerdo al grado del polinomio ingresado para el modelo\n",
        "    X = potenciaPolinomio(X,grado)\n",
        "    \n",
        "    #X es la matriz de datos extendida. W es el vector de parámetros del modelo\n",
        "    #Extendemos la matriz\n",
        "\n",
        "    unos = np.array([np.ones(np.size(X,0))])\n",
        "   \n",
        "    #Concatenamos el vector de unos con la matriz X\n",
        "    X = np.concatenate((unos.T, X), axis=1)\n",
        "    X = X.reshape(np.size(X,0),np.size(X,1))  \n",
        "    \n",
        "    Y = Y.reshape(np.size(Y), 1)\n",
        "    \n",
        "    #Tomamos el número de variables del problema\n",
        "    d = np.size(X,1)  \n",
        "    \n",
        "    #Tomamos el número de muestras de la base de datos\n",
        "    N = np.size(X,0)\n",
        "    \n",
        "    #Inicializamos el vector de parámetros aleatoriamente\n",
        "    Want = np.zeros(d) #d\n",
        "    Want = Want.reshape(np.size(Want),1)\n",
        "    \n",
        "    eta = eta\n",
        "    \n",
        "    iteraciones = iterations\n",
        "    ecms = np.zeros(iteraciones)\n",
        "   \n",
        "    for iter in range(iteraciones):\n",
        "        error = ECM(regression(X,Want),Y)\n",
        "        ecms[iter] = error\n",
        "        #Aquí debe completar el código con la regla de actualización de los\n",
        "        #parámetros W. Tenga en cuenta los nombres de las variables ya creadas:\n",
        "        #Want, X, Y\n",
        "        #Nota: si usa la notación matricial esto puede hacerse en dos líneas de\n",
        "        #código.\n",
        "        \n",
        "\n",
        "    \n",
        "    W = Want  \n",
        "    print ('Vector de parámetros del modelo:\\n')\n",
        "    print ('\\nError Final = ' + str(np.min(ecms)))\n",
        "    \n",
        "    #Aquí debe completar el código para realizar la gráfica de ecms vs. iteraciones\n",
        "    #ecms en el eje de las ordenadas (vertical); iteraciones en el eje de las abscisas.\n",
        "   # plt.scatter(X,Y)\n",
        "   # plt.show()\n",
        "    return W\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unos = np.array([np.ones(np.size(X,0))])\n",
        "print(np.size(X,0))\n",
        "print(unos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5GtaPu9Pmel",
        "outputId": "6243580d-3b5c-4655-f7b3-69b292783447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "[[1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUDKRdP9WQVB"
      },
      "source": [
        "## Ejercicio 3\n",
        "\n",
        "A continuación, se leen los datos de un problema de regresión que consiste en predecir el valor de la variable denominada total_UPDRS. Este conjunto de datos está compuesto por un conjunto de variable que consisten en medidas de la voz, tomadas a 42 personas con enfermedad de parkinson en etapa temprana. A partir de la predicción de la variable total_UPDRS se pueden tomar decisiones que pueden ayudar a afrontar este problema de salud. Para mayor información sobre le dataset y el problema, lea el archivo Documentación_Base_de_Datos o vaya a: https://archive.ics.uci.edu/ml/datasets/Parkinsons+Telemonitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "AoRQ1SnxWQVB",
        "outputId": "e74fe964-8a19-4e3f-aab7-3099e3d0bdea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   subject#  age  sex  test_time  Jitter(%)  Jitter(Abs)  Jitter:RAP  \\\n",
              "0         1   72    0     5.6431    0.00662     0.000034     0.00401   \n",
              "1         1   72    0    12.6660    0.00300     0.000017     0.00132   \n",
              "2         1   72    0    19.6810    0.00481     0.000025     0.00205   \n",
              "3         1   72    0    25.6470    0.00528     0.000027     0.00191   \n",
              "4         1   72    0    33.6420    0.00335     0.000020     0.00093   \n",
              "\n",
              "   Jitter:PPQ5  Jitter:DDP  Shimmer  ...  Shimmer:APQ3  Shimmer:APQ5  \\\n",
              "0      0.00317     0.01204  0.02565  ...       0.01438       0.01309   \n",
              "1      0.00150     0.00395  0.02024  ...       0.00994       0.01072   \n",
              "2      0.00208     0.00616  0.01675  ...       0.00734       0.00844   \n",
              "3      0.00264     0.00573  0.02309  ...       0.01106       0.01265   \n",
              "4      0.00130     0.00278  0.01703  ...       0.00679       0.00929   \n",
              "\n",
              "   Shimmer:APQ11  Shimmer:DDA       NHR     HNR     RPDE      DFA      PPE  \\\n",
              "0        0.01662      0.04314  0.014290  21.640  0.41888  0.54842  0.16006   \n",
              "1        0.01689      0.02982  0.011112  27.183  0.43493  0.56477  0.10810   \n",
              "2        0.01458      0.02202  0.020220  23.047  0.46222  0.54405  0.21014   \n",
              "3        0.01963      0.03317  0.027837  24.445  0.48730  0.57794  0.33277   \n",
              "4        0.01819      0.02036  0.011625  26.126  0.47188  0.56122  0.19361   \n",
              "\n",
              "   total_UPDRS  \n",
              "0       34.398  \n",
              "1       34.894  \n",
              "2       35.389  \n",
              "3       35.810  \n",
              "4       36.375  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38689150-ea43-4f8e-a1e8-5a047783400f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject#</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>test_time</th>\n",
              "      <th>Jitter(%)</th>\n",
              "      <th>Jitter(Abs)</th>\n",
              "      <th>Jitter:RAP</th>\n",
              "      <th>Jitter:PPQ5</th>\n",
              "      <th>Jitter:DDP</th>\n",
              "      <th>Shimmer</th>\n",
              "      <th>...</th>\n",
              "      <th>Shimmer:APQ3</th>\n",
              "      <th>Shimmer:APQ5</th>\n",
              "      <th>Shimmer:APQ11</th>\n",
              "      <th>Shimmer:DDA</th>\n",
              "      <th>NHR</th>\n",
              "      <th>HNR</th>\n",
              "      <th>RPDE</th>\n",
              "      <th>DFA</th>\n",
              "      <th>PPE</th>\n",
              "      <th>total_UPDRS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>0.00662</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.00401</td>\n",
              "      <td>0.00317</td>\n",
              "      <td>0.01204</td>\n",
              "      <td>0.02565</td>\n",
              "      <td>...</td>\n",
              "      <td>0.01438</td>\n",
              "      <td>0.01309</td>\n",
              "      <td>0.01662</td>\n",
              "      <td>0.04314</td>\n",
              "      <td>0.014290</td>\n",
              "      <td>21.640</td>\n",
              "      <td>0.41888</td>\n",
              "      <td>0.54842</td>\n",
              "      <td>0.16006</td>\n",
              "      <td>34.398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>12.6660</td>\n",
              "      <td>0.00300</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.00132</td>\n",
              "      <td>0.00150</td>\n",
              "      <td>0.00395</td>\n",
              "      <td>0.02024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00994</td>\n",
              "      <td>0.01072</td>\n",
              "      <td>0.01689</td>\n",
              "      <td>0.02982</td>\n",
              "      <td>0.011112</td>\n",
              "      <td>27.183</td>\n",
              "      <td>0.43493</td>\n",
              "      <td>0.56477</td>\n",
              "      <td>0.10810</td>\n",
              "      <td>34.894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>19.6810</td>\n",
              "      <td>0.00481</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.00205</td>\n",
              "      <td>0.00208</td>\n",
              "      <td>0.00616</td>\n",
              "      <td>0.01675</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00734</td>\n",
              "      <td>0.00844</td>\n",
              "      <td>0.01458</td>\n",
              "      <td>0.02202</td>\n",
              "      <td>0.020220</td>\n",
              "      <td>23.047</td>\n",
              "      <td>0.46222</td>\n",
              "      <td>0.54405</td>\n",
              "      <td>0.21014</td>\n",
              "      <td>35.389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6470</td>\n",
              "      <td>0.00528</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.00191</td>\n",
              "      <td>0.00264</td>\n",
              "      <td>0.00573</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>...</td>\n",
              "      <td>0.01106</td>\n",
              "      <td>0.01265</td>\n",
              "      <td>0.01963</td>\n",
              "      <td>0.03317</td>\n",
              "      <td>0.027837</td>\n",
              "      <td>24.445</td>\n",
              "      <td>0.48730</td>\n",
              "      <td>0.57794</td>\n",
              "      <td>0.33277</td>\n",
              "      <td>35.810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6420</td>\n",
              "      <td>0.00335</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.00093</td>\n",
              "      <td>0.00130</td>\n",
              "      <td>0.00278</td>\n",
              "      <td>0.01703</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00679</td>\n",
              "      <td>0.00929</td>\n",
              "      <td>0.01819</td>\n",
              "      <td>0.02036</td>\n",
              "      <td>0.011625</td>\n",
              "      <td>26.126</td>\n",
              "      <td>0.47188</td>\n",
              "      <td>0.56122</td>\n",
              "      <td>0.19361</td>\n",
              "      <td>36.375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38689150-ea43-4f8e-a1e8-5a047783400f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38689150-ea43-4f8e-a1e8-5a047783400f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38689150-ea43-4f8e-a1e8-5a047783400f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#cargamos la bd que está en un archivo txt y ahora la podemos manejar de forma matricial\n",
        "#db = pd.read_csv('DB_Parkinson.xlsx', delimiter='\\t')  # Assuming tab-delimiter\n",
        "db =pd.read_excel('DB_Parkinson.xlsx')  # Assuming tab-delimiter\n",
        "db.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioTMEBQMWQVD"
      },
      "source": [
        "A continuación las variables o caracterísicas son guardadas en la variable $X$ que posteriormente es estandarizada y la variable de salida o variable a predecir es guardada en la variable Y. Complete el código llamando a la función gradiente_descendente y pasándole los parámetros correspondientes. Debe obtener como salída el vector de parámetros W estimado y la gráfica del error cuadrático medio vs iteraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESvMU5IcWQVD"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X = db.iloc[:,0:20].to_numpy()\n",
        "Y = db.iloc[:,20].to_numpy()\n",
        "\n",
        "#Estandarización de los datos\n",
        "#La importancia de esto la veremos más adelante en el curso\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)\n",
        "\n",
        "#Partimos la base de datos en dos partes, una para entrenar y otra para validar.\n",
        "#Esto lo veremos con mayor detalle más adelante en el curso.\n",
        "X_train = X[0:4876,0:20]\n",
        "Y_train = Y[0:4876]\n",
        "\n",
        "X_test = X[4876:,0:20]\n",
        "Y_test = Y[4876:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15maaWGtWQVD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "d8440ff2-1647-40fb-f7b9-abb4eb230aa8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-5420f612ad1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#(X_train, Y_train). Use 1000 iteraciones para el laboratorio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0miteraciones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgradiente_descendente\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrado\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miteraciones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-96-371dc46fda1e>\u001b[0m in \u001b[0;36mgradiente_descendente\u001b[0;34m(X, Y, grado, eta, iterations)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#parámetros W. Tenga en cuenta los nombres de las variables ya creadas:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m#Want, X, Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;31m#Nota: si usa la notación matricial esto puede hacerse en dos líneas de\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m#código.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (1000,) and (5875,21) not aligned: 1000 (dim 0) != 5875 (dim 0)"
          ]
        }
      ],
      "source": [
        "eta = 0.001\n",
        "grado = 1\n",
        "\n",
        "#Complete la siguiente línea de código llamando el método gradiente_descendente\n",
        "#con sus respectivos argumentos. Use solo las muestras marcadas para entrenamiento\n",
        "#(X_train, Y_train). Use 1000 iteraciones para el laboratorio\n",
        "iteraciones = 1000\n",
        "W =  gradiente_descendente(X,Y,grado,eta,iteraciones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLe4vK-LWQVE"
      },
      "source": [
        "3.1 Cuántas muestras tiene la base de datos?\n",
        "\n",
        "3.2 Cuántas caracteristicas tiene el problema?\n",
        "\n",
        "3.3 Cuál es el número de coeficientes w que se obtienen al ingresar un polinomio de grado 4? por qué?\n",
        "\n",
        "3.4 Cuántas muestras se usarán para entrenar y cuántas para validar el modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX0C-pA1WQVE"
      },
      "source": [
        "Responda aquí:\n",
        "\n",
        "3.1 R/: \n",
        "\n",
        "3.2 R/: \n",
        "\n",
        "3.3 R/:\n",
        "\n",
        "3.4 R/:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHYszKapWQVE"
      },
      "source": [
        "## Ejercicio 4\n",
        "\n",
        "Identifique la variable \"grado\" (M según el modelo visto en clase) en el código anterior, cambie su valor de acuerdo a la siguiente tabla y complete la columna ECM.\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Tasa de aprendizaje</th>\n",
        "    <th>Grado del polinomio</th>\n",
        "    <th>Error Cuadrático Medio (ECM)</th>\n",
        "  </tr>\n",
        "    \n",
        " <tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td></td>\n",
        "  </tr> \n",
        "  <tr>\n",
        "    <td></td>\n",
        "    <td>2</td>\n",
        "    <td></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td></td>\n",
        "    <td>3</td>\n",
        "    <td></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td></td>\n",
        "    <td>4</td>\n",
        "    <td></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0.001</td>\n",
        "    <td>5</td>\n",
        "    <td>53.69796</td>\n",
        "  </tr>\n",
        "  \n",
        "  <tr>\n",
        "    <td></td>\n",
        "    <td>6</td>\n",
        "    <td></td>\n",
        "  </tr> \n",
        "  <tr>\n",
        "    <td></td>\n",
        "    <td>7</td>\n",
        "    <td></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td></td>\n",
        "    <td>8</td>\n",
        "    <td></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td></td>\n",
        "    <td>9</td>\n",
        "    <td></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td></td>\n",
        "    <td>10</td>\n",
        "    <td></td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "\n",
        "Tenga en cuenta que cuando el valor de $\\eta$ sea $0.001$ y el grado del polinomio sea $5$, el valor del ECM debe ser $53.69796$. Esto le servirá de criterio de verificación para la implementación de su algorítmo de gradiente descendente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKHpPW2iWQVF"
      },
      "source": [
        "## Ejericio 5\n",
        "\n",
        "Con el mejor modelo entrenado (menor ECM), haga la predicción para todos las muestras X_test y calcule el ECM teniendo en cuenta los valores teóricos de salida Y_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgBbxHJJWQVF"
      },
      "outputs": [],
      "source": [
        "#Escriba su código aquí"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmxv-30eWQVF"
      },
      "source": [
        "5.1 Qué diferencia nota en cuánto a los resultados en entrenamiento y en validación?\n",
        "\n",
        "R/:\n",
        "\n",
        "5.2 Por qué cree que ocurre lo anterior?\n",
        "\n",
        "R/:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBaXDIVkWQVF"
      },
      "source": [
        "### Nota\n",
        "\n",
        "Tenga en cuenta que los resultados de este modelo se pueden mejorar incrementando las iteraciones, pero realizaron 1000 para evitar altos costos computacionales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zel6LbhoWQVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc12eab-da1f-4840-858a-46d8efa3eb54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 5 6]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "a = [[1,2,3],[4,5,6],[7,8,9]]\n",
        "m = pd.DataFrame(a)\n",
        "p = m.iloc[1].to_numpy()\n",
        "print(p)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}